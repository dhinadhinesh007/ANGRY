{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Particle Swarm Optimization </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import Utils\n",
    "import PSO\n",
    "import numpy as np\n",
    "\n",
    "fn = \"history_ncert_class10/chap_3.txt\" # sys.argv[1]\n",
    "ref_dir_n = \"history_ncert_class10/annotations/chapter3\" # sys.argv[2]\n",
    "\n",
    "# load file\n",
    "document, ref_sum = Utils.load_documents(fn, ref_dir_n)\n",
    "\n",
    "# Pre-process with Stemmer and/or Lemmatizer.\n",
    "processed_doc = Utils.process_document(document)\n",
    "processed_ref_sum = Utils.process_documents(ref_sum)\n",
    "\n",
    "print(processed_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea to  score each sentence in the input document and choose top n sentences as the summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of PSO is to extract features from our document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "features = PSO.extract_features(processed_doc)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Binary PSO model.\n",
    "model = PSO.Swarm(processed_doc, processed_ref_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with extracted features.\n",
    "weights = model.train(features)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These weights are then used to generate summaries from the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary with weights.\n",
    "p_sum_idx = np.argsort(np.dot(features, weights))[-75:]\n",
    "p_sum = PSO.generate_summary([document[idx] for idx in p_sum_idx])\n",
    "p_sum1 = PSO.join_sentences([processed_doc[idx] for idx in p_sum_idx])\n",
    "ref_sum = PSO.join_docs(processed_ref_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"predicted_summary.txt\", 'w', encoding='utf-8')\n",
    "f.write(p_sum)\n",
    "f.close()\n",
    "print(p_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Rouge Score: \", Utils.calculate_rouge(p_sum1, ref_sum, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
